{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YJTcXfDtoXok"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0NGe00gLoGGT"},"source":["# Load data"]},{"cell_type":"code","metadata":{"id":"iT95Su8SfMjP"},"source":["url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n","iris = pd.read_csv(url, header=None, names=['sepal_length','sepal_width', 'petal_length', 'petal_width', 'class'])\n","\n","iris.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"li7AGqDcFmvP"},"source":["# Data cleaning"]},{"cell_type":"markdown","metadata":{"id":"PKXon3a0otVB"},"source":["## Missing values"]},{"cell_type":"markdown","metadata":{"id":"Ei-GzjQKo1GG"},"source":["### Is there any missing value in the dataframe?"]},{"cell_type":"code","metadata":{"id":"49YVo0F4oI8B"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guRYVJd9pBtt"},"source":["### Lets set the values of the rows 10 to 29 of the column 'petal_length' to NaN"]},{"cell_type":"code","metadata":{"id":"gKCk0LN1o7qG"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EROqoxkZp7v5"},"source":["### Which column has the maximum number of missing values?"]},{"cell_type":"code","metadata":{"id":"GlEv8ynap8NI"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fF6PlMJDpK8t"},"source":["### Try to substitute the NaN values with two methods:\n","- replace null values with column mean (apply it to a copy of the dataframe)\n","- replace null values with 1.0\n","\n"]},{"cell_type":"code","metadata":{"id":"_9boOzQUr0m3"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Df_h0mfTpaOZ"},"source":["### Set the first 3 rows as NaN"]},{"cell_type":"code","metadata":{"id":"-T0eBFhWpXZG"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0tL8sTX4pf9y"},"source":["### Delete the rows that have all NaN"]},{"cell_type":"code","metadata":{"id":"6fexAt6vpdC3"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CqU-2aKupl9N"},"source":["### Reset the index so it begins with 0 again"]},{"cell_type":"code","metadata":{"id":"Zrq2CHACpjTc"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B1dJ8XG-xLU8"},"source":["## Duplicates"]},{"cell_type":"markdown","metadata":{"id":"ahy9vSXPygTE"},"source":["### Does the dataframe contain duplicated rows? If any, visualize all duplicated rows (don't omit first or last occurrences)"]},{"cell_type":"code","metadata":{"id":"Aq2iBuO3ylUY"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yJXRV5UG0CwG"},"source":["### Which row is the most repeated?"]},{"cell_type":"code","metadata":{"id":"_U0w1KuIzqB9"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6LbBZ_9NzbgZ"},"source":["### Drop duplicated rows"]},{"cell_type":"code","metadata":{"id":"rdXZ45HNxQW3"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O1ypIIt55RdA"},"source":["## Detect outliers, e.g., values that are higher than 85th percentile and lower than 25th percentile."]},{"cell_type":"code","metadata":{"id":"TvxMBue15WKN"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vu2QLUx52HW2"},"source":["# Data transformation"]},{"cell_type":"markdown","metadata":{"id":"5CDeAKA92Mpf"},"source":["## Replace class values by removing \"Iris-\" prefix (use a dictionary)"]},{"cell_type":"code","metadata":{"id":"0Qw2H74gx5fy"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEaRJK9l4xQa"},"source":["## Delete columns\n","Delete for example class column"]},{"cell_type":"code","metadata":{"id":"5X0WD5Ia44DP"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MG4xuahg4fPo"},"source":["## How to normalize all columns in a dataframe?\n","- Normalize all columns of df by subtracting the column mean and divide by standard deviation.\n","- Range all columns of df such that the minimum value in each column is 0 and max is 1."]},{"cell_type":"code","metadata":{"id":"GaKy-1r74l6m"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4fShsqiU38Aj"},"source":["## Binning and discretization\n","Discretize dataframe columns in 4 bins and get the new value frequency distribution"]},{"cell_type":"code","metadata":{"id":"MSVo9tjS3QCV"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXZelI2jC1mn"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0OPOWVwDbmn"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fh8HK9-BEXag"},"source":["## Binarize categorical data (dummy variables)\n","Based on the prevoius result, binarize all dataframe columns"]},{"cell_type":"code","metadata":{"id":"duP9_h11Ds-X"},"source":[],"execution_count":null,"outputs":[]}]}